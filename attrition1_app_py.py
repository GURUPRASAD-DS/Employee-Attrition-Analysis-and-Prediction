# -*- coding: utf-8 -*-
"""attrition1_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YJskd0sOg95V41M7NroL10MaSXCcUzLB
"""

!pip install streamlit

import streamlit as st
import pickle
import numpy as np

# Load models
lr = pickle.load(open('/content/logistic_model (2).pkl', 'rb'))
rf = pickle.load(open('/content/random_forest_model (3).pkl', 'rb'))
scaler = pickle.load(open('/content/scaler (4).pkl', 'rb'))

st.title("Employee Attrition Prediction")

# Input form for all 30 features

# Existing fields
age = st.number_input("Age", 18, 65, value=35)
monthly_income = st.number_input("Monthly Income", 1000, 20000, value=6500)
job_satisfaction = st.slider("Job Satisfaction", 1, 4, 3)
overtime = st.selectbox("OverTime", ['Yes', 'No'], index=1)

# Additional fields identified from scaler.feature_names_in_
business_travel = st.selectbox("Business Travel", ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently'], index=1)
daily_rate = st.number_input("Daily Rate", 100, 1500, value=800)
department = st.selectbox("Department", ['Sales', 'Research & Development', 'Human Resources'], index=1)
distance_from_home = st.number_input("Distance From Home", 1, 30, value=10)
education = st.slider("Education", 1, 5, 3)
education_field = st.selectbox("Education Field", ['Life Sciences', 'Medical', 'Marketing', 'Other', 'Technical Degree', 'Human Resources'], index=0)
environment_satisfaction = st.slider("Environment Satisfaction", 1, 4, 3)
gender = st.selectbox("Gender", ['Female', 'Male'], index=1)
hourly_rate = st.number_input("Hourly Rate", 30, 100, value=65)
job_involvement = st.slider("Job Involvement", 1, 4, 3)
job_level = st.slider("Job Level", 1, 5, 2)
job_role = st.selectbox("Job Role", ['Sales Executive', 'Research Scientist', 'Laboratory Technician', 'Manufacturing Director', 'Healthcare Representative', 'Manager', 'Sales Representative', 'Research Director', 'Human Resources'], index=1)
marital_status = st.selectbox("Marital Status", ['Single', 'Married', 'Divorced'], index=1)
monthly_rate = st.number_input("Monthly Rate", 2000, 27000, value=14000)
num_companies_worked = st.number_input("Num Companies Worked", 0, 9, value=2)
percent_salary_hike = st.slider("Percent Salary Hike", 11, 25, 15)
performance_rating = st.slider("Performance Rating", 1, 4, 3)
relationship_satisfaction = st.slider("Relationship Satisfaction", 1, 4, 3)
stock_option_level = st.slider("Stock Option Level", 0, 3, 1)
total_working_years = st.number_input("Total Working Years", 0, 40, value=10)
training_times_last_year = st.slider("Training Times Last Year", 0, 6, 2)
work_life_balance = st.slider("Work Life Balance", 1, 4, 3)
years_at_company = st.number_input("Years At Company", 0, 40, value=5)
years_in_current_role = st.number_input("Years In Current Role", 0, 40, value=3)
years_since_last_promotion = st.number_input("Years Since Last Promotion", 0, 15, value=1)
years_with_curr_manager = st.number_input("Years With Curr Manager", 0, 17, value=3)


# Create a dictionary to hold all feature values
feature_values = {
    'Age': age,
    'BusinessTravel': business_travel,
    'DailyRate': daily_rate,
    'Department': department,
    'DistanceFromHome': distance_from_home,
    'Education': education,
    'EducationField': education_field,
    'EnvironmentSatisfaction': environment_satisfaction,
    'Gender': gender,
    'HourlyRate': hourly_rate,
    'JobInvolvement': job_involvement,
    'JobLevel': job_level,
    'JobRole': job_role,
    'JobSatisfaction': job_satisfaction,
    'MaritalStatus': marital_status,
    'MonthlyIncome': monthly_income,
    'MonthlyRate': monthly_rate,
    'NumCompaniesWorked': num_companies_worked,
    'OverTime': overtime, # Keep as 'Yes'/'No' for now, convert later
    'PercentSalaryHike': percent_salary_hike,
    'PerformanceRating': performance_rating,
    'RelationshipSatisfaction': relationship_satisfaction,
    'StockOptionLevel': stock_option_level,
    'TotalWorkingYears': total_working_years,
    'TrainingTimesLastYear': training_times_last_year,
    'WorkLifeBalance': work_life_balance,
    'YearsAtCompany': years_at_company,
    'YearsInCurrentRole': years_in_current_role,
    'YearsSinceLastPromotion': years_since_last_promotion,
    'YearsWithCurrManager': years_with_curr_manager
}

# Reconstruct the feature array in the order the scaler expects, handling OHE
input_features = []
for expected_feature_name in scaler.feature_names_in_:
    # Handle OverTime separately as it's binary
    if expected_feature_name == 'OverTime':
        input_features.append(1 if feature_values['OverTime'] == 'Yes' else 0)
    # Handle numerical features
    elif expected_feature_name in feature_values and isinstance(feature_values[expected_feature_name], (int, float)):
         input_features.append(feature_values[expected_feature_name])
    # Handle one-hot encoded categorical features
    else:
        # Find the corresponding categorical feature name (e.g., 'BusinessTravel' from 'BusinessTravel_Travel_Rarely')
        categorical_feature_name = None
        for cat_feature in ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']:
            if expected_feature_name.startswith(cat_feature + '_'):
                categorical_feature_name = cat_feature
                break

        if categorical_feature_name:
            # Get the selected value for this categorical feature
            selected_value = feature_values[categorical_feature_name]
            # Check if the expected feature name matches the selected category
            if expected_feature_name == f"{categorical_feature_name}_{selected_value}":
                input_features.append(1)
            else:
                input_features.append(0)
        else:
             # This case should ideally not happen if all expected features are covered
             # but include a safeguard.
             st.warning(f"Warning: Could not find a matching input for expected feature: {expected_feature_name}")
             input_features.append(0) # Append 0 or a default value


# Convert the list to a numpy array and reshape for the scaler
features_array = np.array(input_features).reshape(1, -1)


# Debugging: Print the shape of the input features and expected features
st.write(f"Shape of input features array: {features_array.shape}")
st.write(f"Expected number of features by scaler: {scaler.n_features_in_}")


features_scaled = scaler.transform(features_array)

if st.button("Predict Attrition (Logistic)"):
    result = lr.predict(features_scaled)
    st.write("Attrition Prediction (Logistic):", "Leave" if result[0] == 1 else "Stay")

if st.button("Predict Attrition (Random Forest)"):
    result_rf = rf.predict(features_scaled)
    st.write("Attrition Prediction (Random Forest):", "Leave" if result_rf[0] == 1 else "Stay")

"""## Scale and predict

### Subtask:
Apply the `scaler.transform` and `lr.predict` with the correctly formatted input array.

**Reasoning**:
Apply the scaler transformation and make predictions using both the logistic regression and random forest models, then display the results using Streamlit.

## Summary:

### Data Analysis Key Findings

*   The trained `StandardScaler` and logistic regression model expect exactly 30 specific features as input.
*   The initial attempt to reconstruct the input feature array for the Streamlit app resulted in a `ValueError` because the number of features (24) did not match the expected number (30). This indicated an issue with handling categorical features.
*   The refined approach iterates through the expected feature names from the `scaler.feature_names_in_` attribute to correctly reconstruct the input array, ensuring the correct number and order of features, including handling one-hot encoded columns.
*   The Streamlit application was successfully updated to include input fields for all 30 required features and correctly prepares the input data for scaling and prediction.
*   The `StandardScaler` successfully transformed the prepared input features.
*   Both the logistic regression and random forest models successfully made predictions on the scaled input.

### Insights or Next Steps

*   Ensure that the feature engineering (especially one-hot encoding) applied during model training is precisely replicated when preparing new data for prediction to avoid dimension mismatch errors.
*   The `UserWarning` about missing feature names when transforming the numpy array could potentially be avoided by converting the input array back to a pandas DataFrame with the correct column names before scaling, although it did not prevent the code from functioning in this case.
"""